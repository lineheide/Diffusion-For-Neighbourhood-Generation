{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "project_path = \"/home/s184310/3.Project/data\" #\"/home/s184310/3.Project\" the path to ypur project root\n",
    "patch_size = 40 # The size of the patches to use (You will probably need to experiment with this parameter)\n",
    "patch_stride = 20 # The stride used when generating data\n",
    "channels = 1\n",
    "BATCH_SIZE = 5\n",
    "#define the area we use as our test data\n",
    "rect_x_start, rect_x_end = 100, 290 \n",
    "rect_y_start, rect_y_end = 200, 390\n",
    "\n",
    "test_size=0.2\n",
    "random_state=42\n",
    "\n",
    "mask_count = 140\n",
    "T = 1000 #Timesteps\n",
    "\n",
    "\n",
    "epochs = 100 # Try more!\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_images = 4 #number of images shown in plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_array = np.load(f'{project_path}/final_merged_data/50_mapiveg_percent.npy')\n",
    "print(\"Shape of loaded grid array:\", grid_array.shape)\n",
    "\n",
    "grid_array[grid_array == -1] = -2\n",
    "\n",
    "plt.imshow(grid_array, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    min_val = np.nanmin(data, axis=(0, 1), keepdims=True)\n",
    "    max_val = np.nanmax(data, axis=(0, 1), keepdims=True)\n",
    "    normalized_data = (((data - min_val) / (max_val - min_val))*2)-1\n",
    "    return normalized_data, min_val, max_val\n",
    "\n",
    "def denormalize_data(data, min_val, max_val):\n",
    "    return data * (max_val - min_val) + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    mask = data != -2\n",
    "    masked_data = np.where(mask, data, np.nan)  # Replace -2 with np.nan for computation\n",
    "    min_val = np.nanmin(masked_data)\n",
    "    max_val = np.nanmax(masked_data)\n",
    "    normalized_data = np.where(mask, (((data - min_val) / (max_val - min_val)) * 2) - 1, -2)\n",
    "    return normalized_data, min_val, max_val\n",
    "\n",
    "def denormalize_data(data, min_val, max_val):\n",
    "    mask = data != -2\n",
    "    denormalized_data = np.where(mask, data * (max_val - min_val) / 2 + (max_val + min_val) / 2, -2)\n",
    "    return denormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_grid_array, min_val, max_val = normalize_data(grid_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train, Validation, and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(normalized_grid_array, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(\"Data with test set marked\")\n",
    "rectangle = plt.Rectangle((rect_x_start, rect_y_start), \n",
    "                          rect_x_end - rect_x_start, \n",
    "                          rect_y_end - rect_y_start, \n",
    "                          edgecolor='red', \n",
    "                          facecolor='none', \n",
    "                          linewidth=2)\n",
    "plt.gca().add_patch(rectangle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = normalized_grid_array[rect_y_start:rect_y_end,rect_x_start:rect_x_end].copy()\n",
    "normalized_grid_array[rect_y_start:rect_y_end,rect_x_start:rect_x_end] = -3\n",
    "train_data = normalized_grid_array\n",
    "plt.imshow(train_data, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(\"Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(\"Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_output_pairs(data, patch_size=patch_size, stride=patch_stride):\n",
    "    patches = []\n",
    "    for i in range(0,data.shape[0]-patch_size,stride):\n",
    "        for j in range(0,data.shape[1]-patch_size,stride):\n",
    "            current_patch = data[i:patch_size+i,j:patch_size+j].copy()\n",
    "            if not np.any(current_patch == -3): #Remove all patches where test data is recorded\n",
    "                #if not np.all(current_patch == -2): #Remove all patches where no data is recorded\n",
    "                patches.append(current_patch)\n",
    "    return np.array(patches)\n",
    "\n",
    "train_patches = create_input_output_pairs(train_data)\n",
    "test_patches = create_input_output_pairs(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation\n",
    "train_patches, val_patches = train_test_split(train_patches, test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(\"Train inputs shape:\", train_patches.shape)\n",
    "print(\"Val inputs shape:\", val_patches.shape)\n",
    "print(\"Test inputs shape:\", test_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data, mask_pixels=mask_count):\n",
    "        self.data = data\n",
    "        self.mask_pixels = mask_pixels\n",
    "        self.height, self.width = data.shape[1], data.shape[2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        image = torch.tensor(image, dtype=torch.float32)  # Convert to torch tensor\n",
    "\n",
    "        mask = torch.ones_like(image)\n",
    "        num_pixels_to_mask = self.mask_pixels\n",
    "\n",
    "        i = np.random.randint(0, self.height)\n",
    "        j = np.random.randint(0, self.width)\n",
    "        \n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "        queue = deque([(i, j)])\n",
    "        mask[i, j, :] = 0\n",
    "        num_pixels_to_mask -= 1\n",
    "\n",
    "        while queue and num_pixels_to_mask > 0:\n",
    "            ci, cj = queue.popleft()\n",
    "\n",
    "            for di, dj in directions:\n",
    "                ni, nj = ci + di, cj + dj\n",
    "                if 0 <= ni < self.height and 0 <= nj < self.width and mask[ni, nj, 0] == 1:\n",
    "                    mask[ni, nj, :] = 0\n",
    "                    num_pixels_to_mask -= 1\n",
    "                    queue.append((ni, nj))\n",
    "\n",
    "                    if num_pixels_to_mask == 0:\n",
    "                        break\n",
    "\n",
    "        if num_pixels_to_mask > 0:\n",
    "            for i in range(self.height):\n",
    "                for j in range(self.width):\n",
    "                    if num_pixels_to_mask == 0:\n",
    "                        break\n",
    "                    if mask[i, j, 0] == 1:\n",
    "                        mask[i, j, :] = 0\n",
    "                        num_pixels_to_mask -= 1\n",
    "\n",
    "        masked_image = image * mask\n",
    "\n",
    "        return masked_image.permute(2, 0, 1), image.permute(2, 0, 1), mask.permute(2, 0, 1)\n",
    "\n",
    "\n",
    "train_dataset = PatchDataset(train_patches)\n",
    "val_dataset = PatchDataset(val_patches)\n",
    "test_dataset = PatchDataset(test_patches)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Test the dataloader\n",
    "for masked_image, image, mask in train_dataloader:\n",
    "    print(masked_image.shape)\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The forward process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n",
    "    return torch.linspace(start, end, timesteps, device=device)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    \"\"\" \n",
    "    Returns a specific index t of a passed list of values vals\n",
    "    while considering the batch dimension.\n",
    "    \"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t)#.cpu()\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))#.to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=device):\n",
    "    \"\"\" \n",
    "    Takes an image and a timestep as input and \n",
    "    returns the noisy version of it\n",
    "    \"\"\"\n",
    "    x_0 = x_0.to(device)\n",
    "    #noise = torch.randn_like(x_0).to(device)\n",
    "    noise = torch.randn_like(x_0, device=device)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape).to(device)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "    ).to(device)\n",
    "    c1 = sqrt_alphas_cumprod_t * x_0\n",
    "    c2 = c1 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "    return c2, noise\n",
    "\n",
    "\n",
    "# Define beta schedule\n",
    "\n",
    "betas = linear_beta_schedule(timesteps=T)\n",
    "\n",
    "# Pre-calculate different terms for closed form\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate forward diffusion\n",
    "image_masked,image,mask = next(iter(train_dataloader))\n",
    "plt.figure(figsize=(15,15))\n",
    "stepsize = int(T/num_images)\n",
    "\n",
    "def show_tensor_image(image):\n",
    "    # Take first image of batch\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[0, :, :, :] \n",
    "    plt.imshow(image.permute(1, 2, 0).detach().cpu(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "for idx in range(0, T, stepsize):\n",
    "    t = torch.Tensor([idx]).type(torch.int64).to(device)\n",
    "    plt.subplot(1, num_images + 1, int(idx / stepsize) + 1)\n",
    "    img, noise = forward_diffusion_sample(image, t)\n",
    "    show_tensor_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_dataloader))\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Show the first image on the first subplot\n",
    "plt.sca(axes[0])\n",
    "show_tensor_image(sample[1])\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Show the second image on the second subplot\n",
    "plt.sca(axes[1])\n",
    "show_tensor_image(sample[0])\n",
    "axes[1].set_title('Masked Image')\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tensor_image(sample[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The backward process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch).to(device)\n",
    "        if up:\n",
    "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1).to(device)\n",
    "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1).to(device)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1).to(device)\n",
    "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1).to(device)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1).to(device)\n",
    "        self.bnorm1 = nn.BatchNorm2d(out_ch).to(device)\n",
    "        self.bnorm2 = nn.BatchNorm2d(out_ch).to(device)\n",
    "        self.relu  = nn.ReLU().to(device)\n",
    "        \n",
    "    def forward(self, x, t, ):\n",
    "        # First Conv\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        # Time embedding\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        # Extend last 2 dimensions\n",
    "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
    "        # Add time channel\n",
    "        h = h + time_emb\n",
    "        # Second Conv\n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        # Down or Upsample\n",
    "        return self.transform(h)\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        # TODO: Double check the ordering here\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class SimpleUnet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified variant of the Unet architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        image_channels = channels\n",
    "        down_channels = (patch_size, patch_size*2, patch_size*4, patch_size*8, patch_size*16)\n",
    "        up_channels = (patch_size*16, patch_size*8, patch_size*4, patch_size*2, patch_size)\n",
    "        out_dim = channels\n",
    "        time_emb_dim = 32\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(time_emb_dim).to(device),\n",
    "                nn.Linear(time_emb_dim, time_emb_dim).to(device),\n",
    "                nn.ReLU().to(device)\n",
    "            )\n",
    "        \n",
    "        # Initial projection\n",
    "        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1).to(device)\n",
    "\n",
    "        # Downsample\n",
    "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \\\n",
    "                                    time_emb_dim).to(device) \\\n",
    "                    for i in range(len(down_channels)-1)])\n",
    "        # Upsample\n",
    "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \\\n",
    "                                        time_emb_dim, up=True).to(device) \\\n",
    "                    for i in range(len(up_channels)-1)])\n",
    "        \n",
    "        \n",
    "        self.output = nn.Conv2d(up_channels[-1], out_dim, 1).to(device)\n",
    "\n",
    "    def forward(self, x, timestep):\n",
    "        # Embedd time\n",
    "        t = self.time_mlp(timestep)\n",
    "        # Initial conv\n",
    "        x = self.conv0(x)\n",
    "        # Unet\n",
    "        residual_inputs = []\n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residual_inputs.append(x)\n",
    "        for up in self.ups:\n",
    "            residual_x = residual_inputs.pop()\n",
    "            # Add residual x as additional channels\n",
    "            if x.size(2) != residual_x.size(2) or x.size(3) != residual_x.size(3): #MAYBE REMOVE\n",
    "                x = F.interpolate(x, size=(residual_x.size(2), residual_x.size(3)), mode='bilinear', align_corners=False)\n",
    "            x = torch.cat((x, residual_x), dim=1)           \n",
    "            x = up(x, t)\n",
    "        return self.output(x)\n",
    "\n",
    "model = SimpleUnet().to(device)\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Further improvements that can be implemented:**\n",
    "- Residual connections\n",
    "- Different activation functions like SiLU, GWLU, ...\n",
    "- BatchNormalization \n",
    "- GroupNormalization\n",
    "- Attention\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, x_0, t):\n",
    "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
    "    noise_pred = model(x_noisy, t)\n",
    "    return F.mse_loss(noise_pred,noise)\n",
    "    #return F.l1_loss(noise, noise_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, x_0, t):\n",
    "    # Apply the forward diffusion process to generate noisy data\n",
    "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
    "    \n",
    "    # Predict the noise from the noisy data using the model\n",
    "    noise_pred = model(x_noisy, t)\n",
    "    \n",
    "    # Create a mask where True represents values not equal to -2\n",
    "    mask = (x_0 != -2)\n",
    "    \n",
    "    # Apply the mask to filter out -2 values from noise and noise_pred\n",
    "    valid_noise = noise[mask]\n",
    "    valid_noise_pred = noise_pred[mask]\n",
    "    \n",
    "    # Compute the mean squared error loss only for valid values\n",
    "    loss = F.mse_loss(valid_noise_pred, valid_noise)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_timestep(x, t):\n",
    "    \"\"\"\n",
    "    Calls the model to predict the noise in the image and returns \n",
    "    the denoised image. \n",
    "    Applies noise to this image, if we are not in the last step yet.\n",
    "    \"\"\"\n",
    "    betas_t = get_index_from_list(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Call model (current image - noise prediction)\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
    "    \n",
    "    if t == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        noise = torch.randn_like(x, device=device)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
    "\n",
    "@torch.no_grad()\n",
    "def inpainting_plot_image(image, mask):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    stepsize = int(T / num_images)\n",
    "    \n",
    "    # Display the original image\n",
    "    plt.subplot(1, num_images + 1, 1)\n",
    "    show_tensor_image(image.detach().cpu())\n",
    "    plt.title(f\"Original Image\")  # Set the title of the subplot\n",
    "\n",
    "    masked_image = image*mask\n",
    "\n",
    "    image_list = []\n",
    "    image_idx_plot_list = []\n",
    "    \n",
    "    for idx in range(0, T):\n",
    "        t = torch.Tensor([idx]).type(torch.int64).to(device)\n",
    "        img, noise = forward_diffusion_sample(masked_image, t)\n",
    "        if idx % stepsize == 0:\n",
    "            image_idx_plot_list.append(t)            \n",
    "            plt.subplot(1, num_images+1, 1+int(idx/stepsize) + 1)\n",
    "            show_tensor_image(img.detach().cpu())\n",
    "            #plt.title(f\"Timestep {idx}\")\n",
    "        image_list.append((img,t))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # plot backward process\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, num_images, 1)  # this plots the original image\n",
    "    tmp_mask = 1 #\n",
    "    tmp_img = image_list[-1][0]\n",
    "    for idx, (noisy_img,t) in enumerate(image_list[::-1]):\n",
    "        img = (noisy_img*tmp_mask)+(tmp_img*(1-tmp_mask))\n",
    "        tmp_mask = mask\n",
    "        tmp_img = sample_timestep(img,t)\n",
    "        if t in image_idx_plot_list:\n",
    "            plt.subplot(1, num_images, num_images-(int(idx/stepsize)))\n",
    "            show_tensor_image(tmp_img.detach().cpu())\n",
    "            #plt.title(f\"Timestep {idx}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_epoch(model):\n",
    "    loss_value = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, T, (batch[1].shape[0],), device=device).long()\n",
    "        loss = get_loss(model, batch[1].to(device), t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value+=loss.item()\n",
    "    return loss_value/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_epoch(model):\n",
    "    loss_value = 0\n",
    "    for batch in val_dataloader:\n",
    "        t = torch.randint(0, T, (batch[1].shape[0],), device=device).long()\n",
    "        loss = get_loss(model, batch[1].to(device), t)\n",
    "        loss_value+=loss.item()\n",
    "    return loss_value/len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model)\n",
    "    val_loss = val_epoch(model)\n",
    "    print(f\"Epoch {epoch}/{epochs}: Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "    loss_list.append((train_loss,val_loss))\n",
    "    if epoch > 10:\n",
    "        sample = next(iter(train_dataloader))\n",
    "        inpainting_plot_image(sample[1].to(device),sample[2].to(device))\n",
    "        inpainting_plot_image(sample[1].to(device),sample[2].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot([g[0] for g in loss_list], label='Train Loss')\n",
    "\n",
    "# Plot the validation loss\n",
    "plt.plot([g[1] for g in loss_list], color='orange', label='Validation Loss')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model_singlefeature.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model)\n",
    "    val_loss = val_epoch(model)\n",
    "    print(f\"Epoch {epoch}/{epochs}: Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "    loss_list.append((train_loss,val_loss))\n",
    "    if epoch > 4:\n",
    "        sample = next(iter(train_dataloader))\n",
    "        inpainting_plot_image(sample[1].to(device),sample[2].to(device))\n",
    "        inpainting_plot_image(sample[1].to(device),sample[2].to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot([g[0] for g in loss_list], label='Train Loss')\n",
    "\n",
    "# Plot the validation loss\n",
    "plt.plot([g[1] for g in loss_list], color='orange', label='Validation Loss')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model)\n",
    "    val_loss = val_epoch(model)\n",
    "    print(f\"Epoch {epoch}/{epochs}: Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "    loss_list.append((train_loss,val_loss))\n",
    "    if epoch > 55:\n",
    "        sample = next(iter(train_dataloader))\n",
    "        inpainting_plot_image(sample[1].to(device),sample[2].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Plot the training loss\n",
    "plt.plot([g[0] for g in loss_list], label='Train Loss')\n",
    "# Plot the validation loss\n",
    "plt.plot([g[1] for g in loss_list], color='orange', label='Validation Loss')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "@torch.no_grad()\n",
    "def evaluate_model_on_test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    mse_per_channel = np.zeros(channels)\n",
    "    total_batches = 0\n",
    "\n",
    "    for masked_image, original_image, mask in test_dataloader:\n",
    "        masked_image, original_image, mask = masked_image.to(device), original_image.to(device), mask.to(device)\n",
    "        t = torch.randint(0, T, (original_image.shape[0],), device=device).long()\n",
    "        generated_images = model(masked_image, t)\n",
    "        \n",
    "        # Calculate MSE for the single channel, excluding -1 values\n",
    "        for i in range(original_image.shape[0]):\n",
    "            valid_mask = (original_image[i, 0, :, :] != -1)\n",
    "            mse_per_channel[0] += F.mse_loss(\n",
    "                generated_images[i, 0, :, :][valid_mask], \n",
    "                original_image[i, 0, :, :][valid_mask]\n",
    "            ).item()\n",
    "        \n",
    "        total_batches += 1\n",
    "\n",
    "    mse_per_channel /= total_batches\n",
    "    print(\"MSE per channel:\", np.round(mse_per_channel, 3))\n",
    "\n",
    "    # Print 5 examples of original and generated values\n",
    "    num_examples = min(5, original_image.shape[0])\n",
    "    for i in range(num_examples):\n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(\"Original:\", np.round(original_image[i, 0, :, :].cpu().numpy().flatten()[:10], 3))\n",
    "        print(\"Generated:\", np.round(generated_images[i, 0, :, :].cpu().numpy().flatten()[:10], 3))\n",
    "\n",
    "# Assuming the test_dataloader is defined and contains the unknown test dataset\n",
    "evaluate_model_on_test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
