{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Parameters\n",
    "project_path = \"/home/s184310/3.Project/data/final_merged_data\"\n",
    "patch_size = 50\n",
    "patch_stride = 10\n",
    "channels = 26\n",
    "BATCH_SIZE = 4\n",
    "rect_x_start, rect_x_end = 100, 290 \n",
    "rect_y_start, rect_y_end = 200, 390\n",
    "channel_to_display = 6\n",
    "fixed_channel = 13  # Specify which channel to fix, which is vegetation percentage\n",
    "fixed_value_range = (0, 100)  # Range of values to sample from for the fixed channel\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "mask_count = 140\n",
    "T = 1000\n",
    "epochs = 300\n",
    "learning_rate = 0.001\n",
    "num_images = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_array = np.load(f'{project_path}/50_all_data.npy')\n",
    "print(grid_array.shape)\n",
    "# Initialize a list to store the count of valid data points for each channel\n",
    "valid_data_counts = []\n",
    "\n",
    "# Iterate over each channel\n",
    "for channel in range(grid_array.shape[-1]):\n",
    "    # Extract the data for the current channel\n",
    "    channel_data = grid_array[:, :, channel]\n",
    "    \n",
    "    # Count the number of valid data points (not 0 and not -1)\n",
    "    valid_count = np.sum((channel_data != 0) & (channel_data != -1))\n",
    "    \n",
    "    # Append the count to the list\n",
    "    valid_data_counts.append(valid_count)\n",
    "\n",
    "# Find the channel with the maximum valid data points\n",
    "max_valid_channel = np.argmax(valid_data_counts)\n",
    "max_valid_count = valid_data_counts[max_valid_channel]\n",
    "\n",
    "print(f\"Channel with the most valid data: {max_valid_channel}\")\n",
    "print(f\"Number of valid data points in this channel: {max_valid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the grid array and select the channel to display\n",
    "#grid_array = np.load(f'{project_path}/50m_26_features_array.npy')\n",
    "##print(\"Shape of loaded grid array:\", grid_array.shape)\n",
    "\n",
    "# Update all -1 values to -2\n",
    "grid_array[grid_array == -1] = -2\n",
    "\n",
    "# Mask the -2 values by setting them to NaN for visualization\n",
    "#channel_data = np.where(grid_array[:, :, channel_to_display] == -2, np.nan, grid_array[:, :, channel_to_display])\n",
    "channel_data = np.where(grid_array[:, :, channel_to_display] == 0, np.nan, grid_array[:, :, channel_to_display])\n",
    "#channel_data = grid_array[:, :, channel_to_display]\n",
    "\n",
    "# Mask the -1 values by setting them to NaN\n",
    "channel_data = np.where(channel_data == -2, np.nan, channel_data)\n",
    "channel_data = np.where(channel_data == 0, np.nan, channel_data)\n",
    "\n",
    "# Load the dataframe to get column names\n",
    "#df = pd.read_csv('/home/s184310/3.Project/data/merged_mapi_poi_metrics.csv')\n",
    "columns = df.columns\n",
    "\n",
    "# Calculate the actual column index (accounting for starting from the third column)\n",
    "column_index = channel_to_display + 2\n",
    "\n",
    "# Ensure the index is within the range of the dataframe's columns\n",
    "if column_index < len(columns):\n",
    "    column_name = columns[column_index]\n",
    "    title = f\"Original data for {column_name} feature\"\n",
    "else:\n",
    "    title = f\"Original data for channel {channel_to_display}: Column index out of range\"\n",
    "\n",
    "# Plot the data with a perceptually uniform colormap\n",
    "plt.figure(figsize=(10, 8))  # Increase figure size for better coverage visibility\n",
    "plt.imshow(channel_data, cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title(title)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Print the min and max values excluding NaNs to understand the color range\n",
    "min_val = np.nanmin(channel_data)\n",
    "max_val = np.nanmax(channel_data)\n",
    "print(f\"Data range for displayed channel: {min_val} to {max_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/s184310/3.Project/data/final_merged_data/50m_26_features_array.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the grid array and select the channel to display\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m grid_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproject_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/50m_26_features_array.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of loaded grid array:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Update all -1 values to -2\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/s184310/3.Project/data/final_merged_data/50m_26_features_array.npy'"
     ]
    }
   ],
   "source": [
    "# Load the grid array and select the channel to display\n",
    "grid_array = np.load(f'{project_path}/50m_26_features_array.npy')\n",
    "print(\"Shape of loaded grid array:\", grid_array.shape)\n",
    "\n",
    "# Update all -1 values to -2\n",
    "grid_array[grid_array == -1] = -2\n",
    "\n",
    "def normalize_data(data):\n",
    "    # Create a mask for -2 values\n",
    "    mask = (data != -2) & ~np.isnan(data)\n",
    "    \n",
    "    # Compute min and max excluding -2 values, along the third axis (channels)\n",
    "    with np.errstate(all='ignore'):  # Suppress warnings for NaN slices\n",
    "        min_val = np.nanmin(np.where(mask, data, np.nan), axis=(0, 1), keepdims=True)\n",
    "        max_val = np.nanmax(np.where(mask, data, np.nan), axis=(0, 1), keepdims=True)\n",
    "    \n",
    "    # Handle cases where the min and max are NaN (i.e., no valid data points in the channel)\n",
    "    min_val = np.nan_to_num(min_val, nan=0.0)  # Replace NaN with 0.0\n",
    "    max_val = np.nan_to_num(max_val, nan=1.0)  # Replace NaN with 1.0\n",
    "    \n",
    "    # Ensure min_val != max_val to avoid division by zero\n",
    "    scale = np.where(max_val != min_val, max_val - min_val, 1)\n",
    "    \n",
    "    # Normalize data excluding -2 values\n",
    "    normalized_data = np.where(mask, (((data - min_val) / scale) * 2) - 1, -2)\n",
    "    \n",
    "    return normalized_data, min_val, max_val\n",
    "\n",
    "def denormalize_data(data, min_val, max_val):\n",
    "    # Ensure min_val and max_val are numpy arrays\n",
    "    if isinstance(min_val, torch.Tensor):\n",
    "        min_val = min_val.cpu().numpy()\n",
    "    if isinstance(max_val, torch.Tensor):\n",
    "        max_val = max_val.cpu().numpy()\n",
    "    \n",
    "    # Handle NaN values in min and max\n",
    "    min_val = np.nan_to_num(min_val, nan=0.0)\n",
    "    max_val = np.nan_to_num(max_val, nan=1.0)\n",
    "\n",
    "    # Ensure min_val and max_val are 3D for broadcasting (1, channels, 1, 1)\n",
    "    min_val = min_val.reshape(1, -1, 1, 1)\n",
    "    max_val = max_val.reshape(1, -1, 1, 1)\n",
    "\n",
    "    # Create a mask for -2 values\n",
    "    mask = (data != -2) & ~np.isnan(data)\n",
    "\n",
    "    # Ensure min_val != max_val to avoid division by zero\n",
    "    scale = np.where(max_val != min_val, max_val - min_val, 1)\n",
    "\n",
    "    # Denormalize data excluding -2 values\n",
    "    denormalized_data = np.where(mask, (data + 1) / 2 * scale + min_val, -2)\n",
    "\n",
    "    return denormalized_data\n",
    "\n",
    "normalized_grid_array, min_val, max_val = normalize_data(grid_array)\n",
    "test_data = normalized_grid_array[rect_y_start:rect_y_end, rect_x_start:rect_x_end, :].copy()\n",
    "normalized_grid_array[rect_y_start:rect_y_end, rect_x_start:rect_x_end, :] = -3\n",
    "train_data = normalized_grid_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_output_pairs(data, patch_size=patch_size, stride=patch_stride):\n",
    "    patches = []\n",
    "    for i in range(0, data.shape[0] - patch_size, stride):\n",
    "        for j in range(0, data.shape[1] - patch_size, stride):\n",
    "            current_patch = data[i:patch_size + i, j:patch_size + j].copy()\n",
    "            if not np.any(current_patch == -3):\n",
    "                if not np.all(current_patch == -2):\n",
    "                    patches.append(current_patch)\n",
    "    return np.array(patches)\n",
    "\n",
    "train_patches = create_input_output_pairs(train_data)\n",
    "test_patches = create_input_output_pairs(test_data)\n",
    "\n",
    "# Split the dataset into training and validation\n",
    "train_patches, val_patches = train_test_split(train_patches, test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(\"Train inputs shape:\", train_patches.shape)\n",
    "print(\"Val inputs shape:\", val_patches.shape)\n",
    "print(\"Test inputs shape:\", test_patches.shape)\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data, mask_pixels=mask_count, fixed_channel=fixed_channel, fixed_value=None):\n",
    "        self.data = data\n",
    "        self.mask_pixels = mask_pixels\n",
    "        self.height, self.width = data.shape[1], data.shape[2]\n",
    "        self.fixed_channel = fixed_channel\n",
    "        self.fixed_value = fixed_value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        mask = torch.ones_like(image)\n",
    "        num_pixels_to_mask = self.mask_pixels\n",
    "\n",
    "        i = np.random.randint(0, self.height)\n",
    "        j = np.random.randint(0, self.width)\n",
    "        \n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "        queue = deque([(i, j)])\n",
    "        mask[i, j, :] = 0\n",
    "        num_pixels_to_mask -= 1\n",
    "\n",
    "        while queue and num_pixels_to_mask > 0:\n",
    "            ci, cj = queue.popleft()\n",
    "\n",
    "            for di, dj in directions:\n",
    "                ni, nj = ci + di, cj + dj\n",
    "                if 0 <= ni < self.height and 0 <= nj < self.width and mask[ni, nj, 0] == 1:\n",
    "                    mask[ni, nj, :] = 0\n",
    "                    num_pixels_to_mask -= 1\n",
    "                    queue.append((ni, nj))\n",
    "\n",
    "                    if num_pixels_to_mask == 0:\n",
    "                        break\n",
    "\n",
    "        if num_pixels_to_mask > 0:\n",
    "            for i in range(self.height):\n",
    "                for j in range(self.width):\n",
    "                    if num_pixels_to_mask == 0:\n",
    "                        break\n",
    "                    if mask[i, j, 0] == 1:\n",
    "                        mask[i, j, :] = 0\n",
    "                        num_pixels_to_mask -= 1\n",
    "\n",
    "        # Apply the mask to all channels except the fixed channel\n",
    "        for ch in range(image.shape[0]):\n",
    "            if ch != self.fixed_channel:\n",
    "                image[ch] = image[ch] * mask[ch]\n",
    "\n",
    "        # Set the fixed channel to the known value if specified\n",
    "        if self.fixed_value is not None:\n",
    "            image[self.fixed_channel, :, :] = self.fixed_value\n",
    "\n",
    "        condition_value = image[self.fixed_channel, :, :].mean().unsqueeze(0)\n",
    "        condition_channel = torch.tensor([self.fixed_channel], dtype=torch.float32)\n",
    "\n",
    "        return image.permute(2, 0, 1), image.permute(2, 0, 1), mask.permute(2, 0, 1), condition_channel, condition_value\n",
    "\n",
    "train_dataset = PatchDataset(train_patches)\n",
    "val_dataset = PatchDataset(val_patches)\n",
    "test_dataset = PatchDataset(test_patches)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for masked_image, image, mask, condition_channel, condition_value in train_dataloader:\n",
    "    print(masked_image.shape)\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    print(condition_channel.shape)\n",
    "    print(condition_value.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    def f(t):\n",
    "        return torch.cos((t / timesteps + s) / (1 + s) * 0.5 * torch.pi) ** 2\n",
    "    x = torch.linspace(0, timesteps, timesteps + 1).to(device)\n",
    "    alphas_cumprod = f(x) / f(torch.tensor([0]).to(device))\n",
    "    betas = 1 - alphas_cumprod[1:] / alphas_cumprod[:-1]\n",
    "    betas = torch.clip(betas, 0.0001, 0.999).to(device)\n",
    "    return betas\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t).to(t.device)\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=device):\n",
    "    x_0 = x_0.to(device)\n",
    "    noise = torch.randn_like(x_0, device=device)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape).to(device)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "    ).to(device)\n",
    "    c1 = sqrt_alphas_cumprod_t.to(device) * x_0\n",
    "    c2 = c1 + sqrt_one_minus_alphas_cumprod_t.to(device) * noise\n",
    "    return c2, noise.to(device)\n",
    "\n",
    "betas = cosine_beta_schedule(timesteps=T)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_ch).to(device)\n",
    "        if up:\n",
    "            self.conv1 = nn.Conv2d(2 * in_ch, out_ch, 3, padding=1).to(device)\n",
    "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1).to(device)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1).to(device)\n",
    "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1).to(device)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1).to(device)\n",
    "        self.bnorm1 = nn.BatchNorm2d(out_ch).to(device)\n",
    "        self.bnorm2 = nn.BatchNorm2d(out_ch).to(device)\n",
    "        self.relu = nn.ReLU().to(device)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        time_emb = time_emb[(..., ) + (None, ) * 2]  # Extend to match spatial dimensions\n",
    "        h = h + time_emb  # Add time embedding\n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        return self.transform(h)\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "class SimpleUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        image_channels = channels\n",
    "        down_channels = (patch_size, patch_size * 2, patch_size * 4, patch_size * 8, patch_size * 16)\n",
    "        up_channels = (patch_size * 16, patch_size * 8, patch_size * 4, patch_size * 2, patch_size)\n",
    "        out_dim = channels\n",
    "        time_emb_dim = 32\n",
    "        cond_dim = 2  # Channel number and value\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_emb_dim).to(device),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim).to(device),\n",
    "            nn.ReLU().to(device)\n",
    "        )\n",
    "\n",
    "        self.cond_mlp = nn.Sequential(\n",
    "            nn.Linear(cond_dim, time_emb_dim).to(device),\n",
    "            nn.ReLU().to(device)\n",
    "        )\n",
    "\n",
    "        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1).to(device)\n",
    "\n",
    "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i + 1], \n",
    "                                          time_emb_dim).to(device) \n",
    "                    for i in range(len(down_channels) - 1)])\n",
    "    \n",
    "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i + 1], \n",
    "                                        time_emb_dim, up=True).to(device) \n",
    "                    for i in range(len(up_channels) - 1)])\n",
    "        \n",
    "        self.output = nn.Conv2d(up_channels[-1], out_dim, 1).to(device)\n",
    "\n",
    "    def forward(self, x, timestep, condition):\n",
    "        t = self.time_mlp(timestep)\n",
    "        c = self.cond_mlp(condition)\n",
    "        t = t + c  # Combine time and condition embeddings\n",
    "        x = self.conv0(x)\n",
    "        residual_inputs = []\n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residual_inputs.append(x)\n",
    "        for up in self.ups:\n",
    "            residual_x = residual_inputs.pop()\n",
    "            if x.size(2) != residual_x.size(2) or x.size(3) != residual_x.size(3):\n",
    "                x = F.interpolate(x, size=(residual_x.size(2), residual_x.size(3)), mode='bilinear', align_corners=False)\n",
    "            x = torch.cat((x, residual_x), dim=1)\n",
    "            x = up(x, t)\n",
    "        return self.output(x)\n",
    "\n",
    "model = SimpleUnet().to(device)\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_timestep(x, t):\n",
    "    \"\"\"\n",
    "    Calls the model to predict the noise in the image and returns \n",
    "    the denoised image. \n",
    "    Applies noise to this image, if we are not in the last step yet.\n",
    "    \"\"\"\n",
    "    betas_t = get_index_from_list(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Call model (current image - noise prediction)\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
    "    \n",
    "    if t == 0:\n",
    "        return model_mean \n",
    "    else:\n",
    "        noise = torch.randn_like(x)#, device=device)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise #\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inpainting_plot_image(image, mask):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    stepsize = int(T / num_images)\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(1, num_images + 1, 1)\n",
    "    show_tensor_image(image.detach().cpu())\n",
    "    plt.title(f\"Original Image\")  # Set the title of the subplot\n",
    "    \n",
    "    # Display the initial masked image\n",
    "    masked_image = image * mask\n",
    "\n",
    "    image_list = []\n",
    "    image_idx_plot_list = []\n",
    "\n",
    "    # Forward diffusion process\n",
    "    for idx in range(0, T):  # Iterate over all timesteps\n",
    "        t = torch.Tensor([idx]).type(torch.int64).to(device)  # Convert idx to tensor\n",
    "        img, noise = forward_diffusion_sample(masked_image, t, device)  # Apply forward diffusion to generate noisy image\n",
    "        if idx % stepsize == 0:  # Plot the image if the timestep is in the list of timesteps to plot\n",
    "            image_idx_plot_list.append(idx)  # Append the timestep index to the list\n",
    "            plt.subplot(1, num_images + 1, int(idx / stepsize) + 2)  # Create a subplot for the image\n",
    "            show_tensor_image(img.detach().cpu())  # Show the noisy image at this timestep\n",
    "            plt.title(f\"Timestep {idx}\")  # Set the title of the subplot\n",
    "        image_list.append((img, t))  # Save the noisy image and its timestep\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Backward denoising process\n",
    "    plt.figure(figsize=(15, 15))  # Prepare to plot the denoising process\n",
    "    plt.subplot(1, num_images + 1, 1)  # Create a subplot for the masked image\n",
    "    tmp_mask = torch.ones_like(mask)  # Initialize the mask to 1\n",
    "    tmp_img = image_list[-1][0]  # Start with the last noisy image from the forward process\n",
    "\n",
    "    for idx, (noisy_img, t) in enumerate(image_list[::-1]):  # Iterate over the noisy images in reverse order\n",
    "        # Extract the single element from the tensor\n",
    "        t_idx = int(t.item())\n",
    "\n",
    "        # Predict the denoised image at this timestep\n",
    "        tmp_img = sample_timestep(noisy_img, t)  # Predict the denoised image at this timestep\n",
    "\n",
    "        # Combine the noisy image with the progressively denoised image using the mask\n",
    "        img = (noisy_img * tmp_mask) + (tmp_img * (1 - tmp_mask))\n",
    "\n",
    "        # Update the tmp_mask to mask so that after the first step only the originally masked part in the forward process is used\n",
    "        tmp_mask = mask\n",
    "\n",
    "        # Debug prints for denoising process\n",
    "        print(f\"Backward process - Step {idx}, Timestep {t_idx}\")\n",
    "        print(f\"noisy_img min: {noisy_img.min().item()}, max: {noisy_img.max().item()}\")\n",
    "        print(f\"tmp_img min: {tmp_img.min().item()}, max: {tmp_img.max().item()}\")\n",
    "        print(f\"combined_img min: {img.min().item()}, max: {img.max().item()}\")\n",
    "\n",
    "        # Plot the image if the timestep is in the list of timesteps to plot\n",
    "        if t_idx in image_idx_plot_list:\n",
    "            subplot_index = num_images - (image_idx_plot_list.index(t_idx))\n",
    "            print(f\"INSIDE LOOP: Timestep {t_idx}\")\n",
    "            print(f\"original idx: {subplot_index}\")\n",
    "            plt.subplot(1, num_images + 1, subplot_index + 2)  # Correct subplot index for denoised image\n",
    "            show_tensor_image(img.detach().cpu())  # Show denoised image for that step\n",
    "            plt.title(f\"Timestep {t_idx}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, x_0, t, condition):\n",
    "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
    "    noise_pred = model(x_noisy, t, condition)\n",
    "    mask = (x_0 != -2)\n",
    "    valid_noise = noise[mask]\n",
    "    valid_noise_pred = noise_pred[mask]\n",
    "    loss = F.mse_loss(valid_noise_pred, valid_noise)\n",
    "    return loss\n",
    "\n",
    "def train_epoch(model):\n",
    "    loss_value = 0\n",
    "    for masked_image, image, mask, condition_channel, _ in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, T, (image.shape[0],), device=device).long()\n",
    "        condition_value = torch.tensor([random.uniform(*fixed_value_range)], device=device).unsqueeze(0)  # Draw a new value from 0-100\n",
    "        condition = torch.cat((condition_channel, condition_value), dim=1)\n",
    "        loss = get_loss(model, image.to(device), t, condition.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value += loss.item()\n",
    "    return loss_value / len(train_dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_epoch(model):\n",
    "    loss_value = 0\n",
    "    for masked_image, image, mask, condition_channel, condition_value in val_dataloader:\n",
    "        t = torch.randint(0, T, (image.shape[0],), device=device).long()\n",
    "        condition = torch.cat((condition_channel, condition_value), dim=1)\n",
    "        loss = get_loss(model, image.to(device), t, condition.to(device))\n",
    "        loss_value += loss.item()\n",
    "    return loss_value / len(val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model)\n",
    "    val_loss = val_epoch(model)\n",
    "    print(f\"Epoch {epoch}/{epochs}: Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "    loss_list.append((train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "@torch.no_grad()\n",
    "def test_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    for masked_image, image, mask, condition_channel, condition_value in test_dataloader:\n",
    "        condition = torch.cat((condition_channel, condition_value), dim=1)\n",
    "        t = torch.randint(0, T, (image.shape[0],), device=device).long()\n",
    "        x_noisy, _ = forward_diffusion_sample(image.to(device), t, device)\n",
    "        generated_images = []\n",
    "        for i in range(T - 1, -1, -1):\n",
    "            t_i = torch.full((image.shape[0],), i, device=device, dtype=torch.long)\n",
    "            x_noisy = sample_timestep(x_noisy, t_i, condition.to(device))\n",
    "            generated_images.append(x_noisy.cpu().detach().numpy())\n",
    "\n",
    "        # Visualize the results for the first image in the batch\n",
    "        idx = 0\n",
    "        original_image = image[idx].cpu().numpy()\n",
    "        masked_image = masked_image[idx].cpu().numpy()\n",
    "        generated_image = generated_images[0][idx]\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axes[0].imshow(original_image[channel_to_display], cmap='gray')\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[1].imshow(masked_image[channel_to_display], cmap='gray')\n",
    "        axes[1].set_title(\"Masked Image\")\n",
    "        axes[2].imshow(generated_image[channel_to_display], cmap='gray')\n",
    "        axes[2].set_title(\"Generated Image\")\n",
    "        plt.show()\n",
    "\n",
    "        break\n",
    "\n",
    "test_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing for my one example in thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_from_fixed_channel(model, patch, fixed_channel=13, fixed_value=25, mask_pixels=20):\n",
    "    \"\"\"\n",
    "    Generate the other channels based on a fixed value for one channel in a given patch.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model to use for generation.\n",
    "    - patch: The input patch (tensor) to process.\n",
    "    - fixed_channel: The channel to fix to a specific value.\n",
    "    - fixed_value: The value to set for the fixed channel.\n",
    "    - mask_pixels: The number of pixels to mask.\n",
    "    \n",
    "    Returns:\n",
    "    - original_patch: The original patch before modification.\n",
    "    - generated_patch: The generated patch after applying the condition and using the model.\n",
    "    \"\"\"\n",
    "    # Ensure the patch is a tensor and move it to the correct device\n",
    "    patch = torch.tensor(patch, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Mask all channels except the fixed channel\n",
    "    mask = torch.ones_like(patch)\n",
    "    num_pixels_to_mask = mask_pixels\n",
    "\n",
    "    height, width = patch.shape[1], patch.shape[2]\n",
    "    i = np.random.randint(0, height)\n",
    "    j = np.random.randint(0, width)\n",
    "    \n",
    "    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "    queue = deque([(i, j)])\n",
    "    mask[:, i, j] = 0\n",
    "    num_pixels_to_mask -= 1\n",
    "\n",
    "    while queue and num_pixels_to_mask > 0:\n",
    "        ci, cj = queue.popleft()\n",
    "\n",
    "        for di, dj in directions:\n",
    "            ni, nj = ci + di, cj + dj\n",
    "            if 0 <= ni < height and 0 <= nj < width and mask[0, ni, nj] == 1:\n",
    "                mask[:, ni, nj] = 0\n",
    "                num_pixels_to_mask -= 1\n",
    "                queue.append((ni, nj))\n",
    "\n",
    "                if num_pixels_to_mask == 0:\n",
    "                    break\n",
    "\n",
    "    if num_pixels_to_mask > 0:\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                if num_pixels_to_mask == 0:\n",
    "                    break\n",
    "                if mask[0, i, j] == 1:\n",
    "                    mask[:, i, j] = 0\n",
    "                    num_pixels_to_mask -= 1\n",
    "\n",
    "    for ch in range(patch.shape[0]):\n",
    "        if ch != fixed_channel:\n",
    "            patch[ch] = patch[ch] * mask[ch]\n",
    "\n",
    "    # Set the fixed channel to the known value\n",
    "    patch[fixed_channel, :, :] = fixed_value\n",
    "\n",
    "    condition_value = torch.tensor([fixed_value], dtype=torch.float32).to(device)\n",
    "    condition_channel = torch.tensor([fixed_channel], dtype=torch.float32).to(device)\n",
    "    condition = torch.cat((condition_channel, condition_value), dim=0).unsqueeze(0)\n",
    "\n",
    "    t = torch.randint(0, T, (1,), device=device).long()\n",
    "    x_noisy, _ = forward_diffusion_sample(patch.unsqueeze(0), t, device)\n",
    "    generated_patch = []\n",
    "    \n",
    "    for i in range(T - 1, -1, -1):\n",
    "        t_i = torch.full((1,), i, device=device, dtype=torch.long)\n",
    "        x_noisy = sample_timestep(x_noisy, t_i, condition.to(device))\n",
    "        generated_patch.append(x_noisy.cpu().detach().numpy())\n",
    "\n",
    "    original_patch = patch.cpu().numpy()\n",
    "    generated_patch = generated_patch[0][0]\n",
    "\n",
    "    # Print mean values of masked area\n",
    "    for ch in range(patch.shape[0]):\n",
    "        masked_area_original = original_patch[ch][mask[ch].cpu().numpy() == 0]\n",
    "        masked_area_generated = generated_patch[ch][mask[ch].cpu().numpy() == 0]\n",
    "        print(f\"Channel {ch}: Known mean value: {masked_area_original.mean()}, Generated mean value: {masked_area_generated.mean()}\")\n",
    "\n",
    "    return original_patch, generated_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume model is your trained model and test_patches is your test dataset\n",
    "sample_patch = test_patches[0]  # Select a patch from the test set\n",
    "\n",
    "original, generated = generate_from_fixed_channel(model, sample_patch, fixed_channel=13, fixed_value=25, mask_pixels=20)\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(original[channel_to_display], cmap='gray')\n",
    "axes[0].set_title(\"Original Patch\")\n",
    "axes[1].imshow(generated[channel_to_display], cmap='gray')\n",
    "axes[1].set_title(\"Generated Patch\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
